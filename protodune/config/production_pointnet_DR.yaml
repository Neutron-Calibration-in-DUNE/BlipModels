# Test config file for Blip
module:
  module_name:  'production_pointnet_DR'
  module_type:  'ml'
  module_mode:  'training'
  gpu:          True
  gpu_device:   0

dataset:
  # If this is the first time processing the simulation output
  process_simulation: False
  simulation_folder:  ""
  simulation_files:   []

  # Otherwise, we want to just load the resulting data
  dataset_type:   "cluster"
  dataset_folder: ""
  dataset_files:  [
    "pnsNeutrons_output_sim_file_62834405.0.npz",
    "pnsNeutrons_output_sim_file_62834405.1.npz",
    "pnsNeutrons_output_sim_file_62834405.2.npz",
    "pnsNeutrons_output_sim_file_62834405.3.npz",
    "pnsNeutrons_output_sim_file_62834405.4.npz",
    "pnsNeutrons_output_sim_file_62834405.5.npz",
    "pnsNeutrons_output_sim_file_62834405.6.npz",
    "pnsNeutrons_output_sim_file_62834405.7.npz",
    "pnsNeutrons_output_sim_file_62834405.8.npz",
    "pnsNeutrons_output_sim_file_62834405.9.npz",
    "pnsNeutrons_output_sim_file_62834405.10.npz",
    "pnsNeutrons_output_sim_file_62834405.11.npz",
    "pnsNeutrons_output_sim_file_62834405.12.npz",
    "pnsNeutrons_output_sim_file_62834405.13.npz",
    "pnsNeutrons_output_sim_file_62834405.14.npz",
    "pnsNeutrons_output_sim_file_62834405.15.npz",
    "pnsNeutrons_output_sim_file_62834405.16.npz",
    "pnsNeutrons_output_sim_file_62834405.17.npz",
    "pnsNeutrons_output_sim_file_62834405.18.npz",
    "pnsNeutrons_output_sim_file_62834405.19.npz",
    "pnsNeutrons_output_sim_file_62834405.20.npz",
    "pnsNeutrons_output_sim_file_62834405.21.npz",
    "pnsNeutrons_output_sim_file_62834405.22.npz",
    "pnsNeutrons_output_sim_file_62834405.23.npz",
    "pnsNeutrons_output_sim_file_62834405.24.npz",
    "pnsNeutrons_output_sim_file_62834405.25.npz",
    "pnsNeutrons_output_sim_file_62834405.26.npz",
    "pnsNeutrons_output_sim_file_62834405.27.npz",
    "pnsNeutrons_output_sim_file_62834405.28.npz",
    "pnsNeutrons_output_sim_file_62834405.29.npz",
    "pnsNeutrons_output_sim_file_62834405.30.npz",
    "pnsNeutrons_output_sim_file_62834405.31.npz",
    "pnsNeutrons_output_sim_file_62834405.32.npz",
    "pnsNeutrons_output_sim_file_62834405.33.npz",
    "pnsNeutrons_output_sim_file_62834405.34.npz",
    "pnsNeutrons_output_sim_file_62834405.35.npz",
    "pnsNeutrons_output_sim_file_62834405.36.npz",
    "pnsNeutrons_output_sim_file_62834405.37.npz",
    "pnsNeutrons_output_sim_file_62834405.38.npz",
    "pnsNeutrons_output_sim_file_62834405.39.npz",
    "pnsNeutrons_output_sim_file_62834405.40.npz",
    "pnsNeutrons_output_sim_file_62834405.41.npz",
    "pnsNeutrons_output_sim_file_62834405.42.npz",
    "pnsNeutrons_output_sim_file_62834405.43.npz",
    "pnsNeutrons_output_sim_file_62834405.44.npz",
    "pnsNeutrons_output_sim_file_62834405.45.npz",
    "pnsNeutrons_output_sim_file_62834405.46.npz",
    "pnsNeutrons_output_sim_file_62834405.47.npz",
    "pnsNeutrons_output_sim_file_62834405.48.npz",
    "pnsNeutrons_output_sim_file_62834405.49.npz",
  ]

  positions:  ["channel", "tdc", "adc"]
  features:   []
  classes:    ["particle"]
  clusters:   []
  
  # We only want to cluster shapes which are blips
  class_mask: "shape"
  label_mask: "blip"

  # clustering related parameters
  dbscan_min_samples: 6
  dbscan_eps:         10.0
  cluster_positions:  ["channel", "tdc"]

  # we can regroup classes to reduce their number,
  # e.g., say we want to train so that there are
  # only two important shapes, "blip" and "not-blip",
  # then we would consolidate like below:
  consolidate_classes:  
  #   shape:  [["blip"], [""]]
  
  sample_weights: []
  class_weights:  []
  normalized:     False
  root:           "."
  skip_processing:  False
  transform:      null
  pre_transform:  null
  pre_filter:     null

loader:
  batch_size:       32
  test_split:       0.1
  test_seed:        100
  validation_split: 0.2
  validation_seed:  101
  num_workers:      4
  sparse:           True

training:
  epochs:       100
  checkpoint:   10
  progress_bar: 'all'   # train, validation, test, all
  rewrite_bar:  False   # wether to leave bars after each epoch
  save_predictions: True  # wether to save network outputs in original file
  no_timing:  False     # wether to keep timing/memory info in callback
  seed:       42

model:
  # uncomment the line below and specify the model to load from a checkpoint.
  # load_model:   ".checkpoints/checkpoint_200.ckpt"

  # multiple options for model_type: 
  # [ "single", "composite", ... ]
  model_type: "single"
  PointNet: 
    input_dimension:      3
    classifications:      ["particle"]
    augmentations:
      jitter: 0.03
      flip:
        positions:     [0, 1]
        probabilities: [0.5, 0.5]
      shear:  0.2
    number_of_augmentations:  5
    embedding_type:       "dynamic_edge_conv"
    number_of_embeddings: 4
    number_of_neighbors:  [5, 10, 20, 30]    
    aggregation:          ["max", "max", "max", "max"]
    embedding_mlp_layers: [
      [5, 10, 25, 10],
      [10, 25, 50, 25],
      [20, 30, 40, 30],
      [30, 50, 75, 50]
    ]
    linear_output:        128
    mlp_output_layers:    [128, 256, 32]
    out_channels:         [32]
  
criterion:
  MultiClassProbabilityLoss:
    alpha:    1.0
    classes:  ["particle"]
  NTXEntropyLoss:
    alpha:  1.0
    classes:  ["reductions"]
    
metrics:
  ConfusionMatrixMetric:
    mode:   "cluster"
    inputs: ["particle"]
    number_of_classes: [32]

callbacks:
  LossCallback:
  ConfusionMatrixCallback:
    sig_acceptance: [0.1, 0.5, 0.9]

optimizer:
  optimizer_type: "Adam"
  learning_rate:  0.01
  betas:          [0.9, 0.999]
  epsilon:        1e-08
  weight_decay:   0.001
  momentum:       0.9