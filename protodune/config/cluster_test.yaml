# Test config file for Blip
module:
  module_type:  'clustering'
  gpu:          True
  gpu_device:   0

dataset:
  # If this is the first time processing the simulation output
  process_simulation: False
  simulation_folder:  "/home/ncarrara/physics/DUNE/BlipModels/protodune/data/"
  simulation_files:   [
    "protodune_mc_0.root",
    "protodune_mc_1.root",
    "protodune_mc_2.root",
    "protodune_mc_3.root",
    "protodune_mc_4.root",
    "protodune_mc_5.root",
    "protodune_mc_6.root",
    "protodune_mc_7.root",
    "protodune_mc_8.root",
    "protodune_mc_9.root",
    "protodune_mc_10.root",
  ]

  # Otherwise, we want to just load the resulting data
  dataset_type:   "voxel"
  dataset_folder: "/home/ncarrara/physics/DUNE/BlipModels/protodune/data/"
  dataset_files:  [
    "blip_simulation_0/view1_tpc0.npz",
    "blip_simulation_0/view1_tpc2.npz",
    "blip_simulation_0/view1_tpc4.npz",
    "blip_simulation_0/view1_tpc6.npz",
    "blip_simulation_0/view1_tpc8.npz",
    "blip_simulation_0/view1_tpc10.npz",
  ]

  positions:  ["channel", "tdc"]
  features:   ["adc"]
  classes:    ["particle"]
  clusters:   ["particle"]
  # We only want to cluster shapes which are blips
  class_mask: "shape"
  label_mask: "blip"

  # we can regroup classes to reduce their number,
  # e.g., say we want to train so that there are
  # only two important shapes, "blip" and "not-blip",
  # then we would consolidate like below:
  consolidate_classes:  
  #   shape:  [["blip"], [""]]
  
  sample_weights: []
  class_weights:  []
  normalized:     False
  root:           "."
  skip_processing:  False
  transform:      null
  pre_transform:  null
  pre_filter:     null

loader:
  batch_size:       32
  test_split:       0.1
  test_seed:        100
  validation_split: 0.2
  validation_seed:  101
  num_workers:      4

clusterer:
  num_parameters: 100
  eps_range:      [1.0, 100.00]
  progress_bar: True   
  rewrite_bar:  False   # wether to leave bars after each epoch
  save_predictions: True  # wether to save outputs in original file
  no_timing:  False     # wether to keep timing/memory info in callback
  seed:       42

clustering_algorithms:
  DBSCAN:
    eps:          10.0
    min_samples:  10

metrics:
  AdjustedRandIndexMetric:
    inputs: ["DBSCAN"]

callbacks: