# Test config file for Blip
module:
  
  module_name:  'unet_test'
  module_type:  'ml'
  module_mode:  'training'
  gpu:          True
  gpu_device:   0

dataset:
  # If this is the first time processing the simulation output
  process_simulation: False
  process_type:       'all'
  simulation_folder:  "/home/ncarrara/physics/DUNE/BlipModels/protodune/data/"
  simulation_files:   [
    "protodune_mc_0.root",
    "protodune_mc_1.root",
    "protodune_mc_2.root",
    "protodune_mc_3.root",
    "protodune_mc_4.root",
    "protodune_mc_5.root",
    "protodune_mc_6.root",
    "protodune_mc_7.root",
    "protodune_mc_8.root",
    "protodune_mc_9.root",
    "protodune_mc_10.root",
  ]

  # Otherwise, we want to just load the resulting data
  dataset_type:   "voxel"
  dataset_folder:  "/home/ncarrara/physics/DUNE/BlipModels/protodune/data/"
  dataset_files:  [
    "protodune_mc_0/view1_tpc0.npz",
    "protodune_mc_0/view1_tpc2.npz",
    "protodune_mc_0/view1_tpc4.npz",
    "protodune_mc_0/view1_tpc6.npz",
    "protodune_mc_0/view1_tpc8.npz",
    "protodune_mc_0/view1_tpc10.npz",
    "protodune_mc_1/view1_tpc0.npz",
    "protodune_mc_1/view1_tpc2.npz",
    "protodune_mc_1/view1_tpc4.npz",
    "protodune_mc_1/view1_tpc6.npz",
    "protodune_mc_1/view1_tpc8.npz",
    "protodune_mc_1/view1_tpc10.npz",
    "protodune_mc_2/view1_tpc0.npz",
    "protodune_mc_2/view1_tpc2.npz",
    "protodune_mc_2/view1_tpc4.npz",
    "protodune_mc_2/view1_tpc6.npz",
    "protodune_mc_2/view1_tpc8.npz",
    "protodune_mc_2/view1_tpc10.npz",
    "protodune_mc_3/view1_tpc0.npz",
    "protodune_mc_3/view1_tpc2.npz",
    "protodune_mc_3/view1_tpc4.npz",
    "protodune_mc_3/view1_tpc6.npz",
    "protodune_mc_3/view1_tpc8.npz",
    "protodune_mc_3/view1_tpc10.npz",
    "protodune_mc_4/view1_tpc0.npz",
    "protodune_mc_4/view1_tpc2.npz",
    "protodune_mc_4/view1_tpc4.npz",
    "protodune_mc_4/view1_tpc6.npz",
    "protodune_mc_4/view1_tpc8.npz",
    "protodune_mc_4/view1_tpc10.npz",
    "protodune_mc_5/view1_tpc0.npz",
    "protodune_mc_5/view1_tpc2.npz",
    "protodune_mc_5/view1_tpc4.npz",
    "protodune_mc_5/view1_tpc6.npz",
    "protodune_mc_5/view1_tpc8.npz",
    "protodune_mc_5/view1_tpc10.npz",
    "protodune_mc_6/view1_tpc0.npz",
    "protodune_mc_6/view1_tpc2.npz",
    "protodune_mc_6/view1_tpc4.npz",
    "protodune_mc_6/view1_tpc6.npz",
    "protodune_mc_6/view1_tpc8.npz",
    "protodune_mc_6/view1_tpc10.npz",
    "protodune_mc_7/view1_tpc0.npz",
    "protodune_mc_7/view1_tpc2.npz",
    "protodune_mc_7/view1_tpc4.npz",
    "protodune_mc_7/view1_tpc6.npz",
    "protodune_mc_7/view1_tpc8.npz",
    "protodune_mc_7/view1_tpc10.npz",
    "protodune_mc_8/view1_tpc0.npz",
    "protodune_mc_8/view1_tpc2.npz",
    "protodune_mc_8/view1_tpc4.npz",
    "protodune_mc_8/view1_tpc6.npz",
    "protodune_mc_8/view1_tpc8.npz",
    "protodune_mc_8/view1_tpc10.npz",
    "protodune_mc_9/view1_tpc0.npz",
    "protodune_mc_9/view1_tpc2.npz",
    "protodune_mc_9/view1_tpc4.npz",
    "protodune_mc_9/view1_tpc6.npz",
    "protodune_mc_9/view1_tpc8.npz",
    "protodune_mc_9/view1_tpc10.npz",
    "protodune_mc_10/view1_tpc0.npz",
    "protodune_mc_10/view1_tpc2.npz",
    "protodune_mc_10/view1_tpc4.npz",
    "protodune_mc_10/view1_tpc6.npz",
    "protodune_mc_10/view1_tpc8.npz",
    "protodune_mc_10/view1_tpc10.npz",
  ]
  positions:  ["channel", "tdc"]
  features:   ["adc"]
  classes:    ["shape"]
  clusters:   ["particle"]
  # we can regroup classes to reduce their number,
  # e.g., say we want to train so that there are
  # only two important shapes, "blip" and "not-blip",
  # then we would consolidate like below:
  consolidate_classes:  
  #   shape:  [["blip"], ["track"], [""]]
  
  sample_weights: []
  class_weights:  []
  normalized:     False
  root:           "."
  skip_processing:  False
  transform:      null
  pre_transform:  null
  pre_filter:     null

loader:
  batch_size:       3
  test_split:       0.1
  test_seed:        100
  validation_split: 0.2
  validation_seed:  100
  num_workers:      4
  sparse:           True

training:
  epochs:       150
  checkpoint:   10
  progress_bar: 'all'   # train, validation, test, all
  rewrite_bar:  False   # wether to leave bars after each epoch
  save_predictions: True  # wether to save network outputs in original file
  no_timing:  False     # wether to keep timing/memory info in callback
  seed:       42

model:
  # uncomment the line below and specify the model
  # to load from a checkpoint.
  # load_model:   ".checkpoints/checkpoint_200.ckpt"

  # multiple options for model_type: 
  # [ "SparseUNet", "PointNet", "UNet", ... ]
  # or a Composite.
  model_type:       "single"
  SparseUResNet:  
    in_channels:      1
    classifications:  ["shape"]               # {"source", "shape", "particle"}
    out_channels:     [7]                     # {8, 7, 32}
    filtrations:      [64, 128, 256, 512]     # the number of filters in each downsample
    double_conv_params:
      kernel_size:  3
      stride:       1
      dilation:     1
      activation:   "relu"
      dimension:    2
      batch_norm:   True
    conv_transpose_params:
      kernel_size:  2
      stride:       2
      dilation:     1
      dimension:    2
    max_pooling_params:
      kernel_size:  2
      stride:       2
      dilation:     1
      dimension:    2
    
hyperparameters:
  filtrations:  [
    [64, 128, 256, 512],
    [32, 64, 128, 256, 512, 1024]
  ]
  double_conv_params:
    kernel_size:  [2, 3, 4, 5]

criterion:
  MultiClassCrossEntropyLoss:
    alpha:  1.0
    classes:  ["shape"]
    
metrics:
  ConfusionMatrixMetric:
    mode:   "voxel"
    inputs: ["shape"]
    number_of_classes: [7]

callbacks:
  LossCallback:
  ConfusionMatrixCallback:
    sig_acceptance: [0.1, 0.5, 0.9]

optimizer:
  optimizer_type: "Adam"
  learning_rate:  0.01
  betas:          [0.9, 0.999]
  epsilon:        1e-08
  weight_decay:   0.001
  momentum:       0.9
